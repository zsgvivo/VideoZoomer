set -euo pipefail

export VLLM_USE_V1=1

TRAIN_DATA_PATH="${TRAIN_DATA_PATH:-/path/to/train.json}"
VAL_DATA_PATH="${VAL_DATA_PATH:-/path/to/val.yaml}"
MODEL_PATH="${MODEL_PATH:-/path/to/model}"
LOG_ROOT="${LOG_ROOT:-/path/to/logs}"
CKPT_ROOT="${CKPT_ROOT:-/path/to/checkpoints}"
PROJECT_NAME="${PROJECT_NAME:-your_project}"
EXPERIMENT_NAME="${EXPERIMENT_NAME:-your_experiment}"
python3 -m verl.trainer.main_ppo \
    algorithm.adv_estimator=grpo \
    data.train_files="${TRAIN_DATA_PATH}" \
    data.val_files="${VAL_DATA_PATH}" \
    data.train_batch_size=128 \
    data.max_prompt_length=20480 \
    data.max_response_length=4096 \
    data.image_key=videos \
    data.video_fps=0.5 \
    data.frames_upbound=64 \
    data.max_pixels=100352 \
    data.min_pixels=25088 \
    data.storage_system=local \
    reward_model.reward_manager=naive_multithreads \
    reward_model.val_reward_manager=naive_multithreads \
    'data.system_prompt="You are a helpful assistant. You will receive a low-frame-rate video and related questions. You can analyze the video content to answer the question and trigger high-frame-rate inspections when finer temporal resolution is needed. When you detect ambiguous motion/objects that require closer inspection, wrap your request in <video_zoom></video_zoom> tags and provide the exact time segment and target frame rate in JSON format: <video_zoom> {\"segment\": [start_sec, end_sec], \"fps\": n} </video_zoom>, it will return the video clip at the target fps to help you better answer the question. Note that the total frames num of the request clip cannot exceed 16 (e.g., (end_sec - start_sec) * fps â‰¤ 16) and DO NOT include <answer> tags in this round. \n Example usage: <video_zoom> {\"segment\": [4.0, 6.0], \"fps\": 2} </video_zoom>. If the initial tool response does not provide sufficient information to answer the question, you may continue to request additional video zoom inspections as needed, until you either (1) gather enough information to form a complete answer, or (2) are explicitly instructed to stop using the tool. Output the thinking process within <think> </think> tags, once you confirm your final answer place the final answer inside <answer> and </answer>."' \
    actor_rollout_ref.model.path="${MODEL_PATH}" \
    actor_rollout_ref.actor.optim.lr=1e-6 \
    actor_rollout_ref.actor.optim.lr_scheduler=constant \
    actor_rollout_ref.actor.clip_ratio_high=0.27 \
    actor_rollout_ref.actor.clip_ratio_low=0.2 \
    actor_rollout_ref.model.use_remove_padding=True \
    actor_rollout_ref.actor.ppo_mini_batch_size=32 \
    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
    actor_rollout_ref.actor.use_kl_loss=True \
    actor_rollout_ref.actor.kl_loss_coef=0.001 \
    actor_rollout_ref.actor.entropy_coeff=0.001 \
    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.fsdp_config.param_offload=False \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1 \
    actor_rollout_ref.rollout.tensor_model_parallel_size=1 \
    actor_rollout_ref.rollout.max_num_batched_tokens=32768 \
    actor_rollout_ref.rollout.name=vllm_video_multiturn \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.7 \
    actor_rollout_ref.rollout.enable_chunked_prefill=False \
    actor_rollout_ref.rollout.enforce_eager=False \
    actor_rollout_ref.rollout.free_cache_engine=False \
    actor_rollout_ref.rollout.tool_call_max_frames=16 \
    actor_rollout_ref.rollout.n=16 \
    actor_rollout_ref.rollout.max_total_response_length=32768 \
    actor_rollout_ref.rollout.max_model_len=32768 \
    actor_rollout_ref.rollout.max_generation_round=5 \
    'actor_rollout_ref.rollout.limit_mm_per_prompt={'image': 128}' \
    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1 \
    actor_rollout_ref.ref.fsdp_config.param_offload=True \
    actor_rollout_ref.rollout.gen_batch_size=64 \
    algorithm.kl_ctrl.kl_coef=0.0 \
    trainer.critic_warmup=0 \
    trainer.logger=['console','wandb'] \
    trainer.project_name="${PROJECT_NAME}" \
    trainer.experiment_name="${EXPERIMENT_NAME}" \
    trainer.log_training_rollouts_freq=5 \
    trainer.train_generations_to_log_to_wandb=256 \
    trainer.val_generations_to_log_to_wandb=128 \
    trainer.tool_call_generations_to_log_to_wandb=10 \
    trainer.n_gpus_per_node=8 \
    trainer.nnodes=2 \
    trainer.save_freq=10 \
    trainer.rejection_sample=True \
    trainer.test_freq=5 \
    trainer.total_epochs=20 \
    trainer.resume_mode=auto \
    "trainer.rollout_data_dir=${LOG_ROOT}/${trainer.project_name}/${trainer.experiment_name}/train" \
    "trainer.validation_data_dir=${LOG_ROOT}/${trainer.project_name}/${trainer.experiment_name}/val" \
    reward_model.log_rewards_separately=True \
    reward_model.acc_reward_weight=0.9 \
    reward_model.format_reward_weight=0.1 \
    reward_model.judge_mc_by_gpt=False \
    reward_model.gpt_extract_answer=True \
    trainer.reflection_keywords=['wait,recheck,alternatively,retry,however,rethink,re-evaluate,hmm,re-check,double-check'] \
    "trainer.default_local_dir=${CKPT_ROOT}/${trainer.project_name}/${trainer.experiment_name}"
